{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f70954",
   "metadata": {},
   "source": [
    "# Test de la librairie de correction orthographique Pyspellchecker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2073a94",
   "metadata": {},
   "source": [
    "La librairie [Pyspellchecker](https://github.com/barrust/pyspellchecker) utilise la distance de Levenshtein pour corriger un mot, en trouvant les permutations possibles selon une distance d'édition de 2 maximum par rapport à la forme corrigée. Elle compare ensuite toutes les permutations (insertions, suppression, remplacements, transpositions) à des mots corrects dans un une liste de fréquence de mots. \n",
    "\n",
    "(\"It uses a Levenshtein Distance algorithm to find permutations within an edit distance of 2 from the original word. It then compares all permutations (insertions, deletions, replacements, and transpositions) to known words in a word frequency list. Those words that are found more often in the frequency list are more likely the correct results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20aad3b",
   "metadata": {},
   "source": [
    "On teste cette librairie pour voir : \n",
    "\n",
    "1. L'efficacité de la correction avec un dictionnaire de prénoms chargé localement\n",
    "2. Si on peut cibler efficacement la correction des mots selon la reconnaissance d'entités nommées, afin d'éviter la surcorrection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d515949d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d51950fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6943dd37",
   "metadata": {},
   "source": [
    "## Chaîne de caractère de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08223f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On stocke une chaîne de caractère test issue d'une sortie d'HTR d'une page de répertoire de notaire\n",
    "test_string = \"Gauther (par Marie Cexandinte) à Paris, rue St Ferdinandt, à sespère et mère\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bb40c2",
   "metadata": {},
   "source": [
    "## On instancie le modèle de langue française avec spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0da94e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entités extraites par la chaîne de traitement spaCy : [('Gauther', 0, 7, 'LOC'), ('Marie Cexandinte', 13, 29, 'PER'), ('Paris', 34, 39, 'LOC'), ('rue St Ferdinandt', 41, 58, 'LOC'), ('sespère', 63, 71, 'PER'), ('mère', 75, 80, 'PER')]\n"
     ]
    }
   ],
   "source": [
    "# On instancie le modèle de langue française avec spaCy\n",
    "nlp = spacy.load('fr_core_news_lg')\n",
    "doc = nlp(test_string)\n",
    "# On stocke les informations relatives au NER\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "print(f\"Entités extraites par la chaîne de traitement spaCy : {ents}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2264057",
   "metadata": {},
   "source": [
    "## Test de correction avec un dictionnaire de prénoms chargé localement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653c213f",
   "metadata": {},
   "source": [
    "Pour ce test, on souhaiterait corriger les entités `PER`, donc des prénoms et des noms, détectés par la chaîne de traitement spaCy. \n",
    "\n",
    "On cible donc les entités `PER` et `MISC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d1b81704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gauther (par Marie Cexandinte) à Paris, rue St Ferdinandt, à sespère et mère\n",
      "\n",
      "\n",
      "Entité à corriger : ('Marie Cexandinte', 13, 29, 'PER')\n",
      "Marie Cexandinte\n",
      "Indice de confiance pour la correction : 0.0\n",
      "Correction : marie cexandinte\n",
      "Candidats trouvées pour la correction : {'marie cexandinte'}\n",
      "-----\n",
      "Entité à corriger : ('sespère', 63, 71, 'PER')\n",
      "sespère\n",
      "Indice de confiance pour la correction : 0.0\n",
      "Correction : sempere\n",
      "Candidats trouvées pour la correction : {'sempere'}\n",
      "-----\n",
      "Entité à corriger : ('mère', 75, 80, 'PER')\n",
      "mère\n",
      "Indice de confiance pour la correction : 0.0\n",
      "Correction : meire\n",
      "Candidats trouvées pour la correction : {'mere', 'meyre', 'meire'}\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# On instancie l'objet SpellChecker en lui passant en paramètre un référentiel stocké localement\n",
    "# Le référentiel fera office de dictionnaire pour corriger\n",
    "# Le référentiel est un référentiel de prénoms\n",
    "spell_custom_dictionary = SpellChecker(local_dictionary='referentiel/firstname.json', case_sensitive=False)\n",
    "\n",
    "print(test_string)\n",
    "print('\\n')\n",
    "\n",
    "# On cible la correction sur les entités PER ou MISC\n",
    "for ent in ents:\n",
    "    if ent[3] == 'PER' or ent[3] == \"MISC\":\n",
    "        print(f\"Entité à corriger : {ent}\")\n",
    "        misspelled = spell_custom_dictionary.unknown([ent[0]])\n",
    "        print(ent[0])\n",
    "        for word in misspelled:\n",
    "            # TODO: comprendre pourquoi cette fonction ne renvoie pas de valeur (seulement 0.0).\n",
    "            # Elle est censée donné un indice de confiance sur la correction\n",
    "            print(f'Indice de confiance pour la correction : {spell_custom_dictionary.word_usage_frequency(word)}')\n",
    "            print(f'Correction : {spell_custom_dictionary.correction(word)}')\n",
    "            print(f'Candidats trouvées pour la correction : {spell_custom_dictionary.candidates(word)}')\n",
    "            print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0a5c91",
   "metadata": {},
   "source": [
    "Eviter la surcorrection a échoué à cause du modèle de NER générique de spaCy. \n",
    "\n",
    "Corriger les noms et les prénoms semble, du moins avec ce que l'on sait faire pour le moment, dangereux car risquant d'induire en erreur la consultion des pages des répertoires des notaires."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87df9038",
   "metadata": {},
   "source": [
    "Par curiosité, on teste pour `Gauther` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0acda5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indice de confiance pour la correction : 0.0\n",
      "Correction : gauthier\n",
      "Candidats trouvées pour la correction : {'gauthe', 'gaucher', 'gautier', 'gauthier', 'gauter', 'gauthey', 'gauthyer'}\n"
     ]
    }
   ],
   "source": [
    "gauther = \"Gauther\"\n",
    "\n",
    "print(f'Indice de confiance pour la correction : {spell_custom_dictionary.word_usage_frequency(gauther)}')\n",
    "print(f'Correction : {spell_custom_dictionary.correction(gauther)}')\n",
    "print(f'Candidats trouvées pour la correction : {spell_custom_dictionary.candidates(gauther)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fcd557",
   "metadata": {},
   "source": [
    "Cette correction simple a été réussie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24f70f1",
   "metadata": {},
   "source": [
    "## Cibler efficacement la correction des mots selon la reconnaissance d'entités nommées, afin d'éviter la surcorrection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07c4ef5",
   "metadata": {},
   "source": [
    "On teste une autre chaîne de caractère issue de la transcription automatique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a02a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string_2 = \"de Goyenèche (à Carmen) dt à Paris, avenue Friedland 15, à la Sté Ste des Coteauxde Bois de Boulogne et de Longchamps, siégeà Paris, rue del'Osly 9, de 3 paralles de terrainmet 1808\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12ce9618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entités extraites par la chaîne de traitement spaCy : [('de Goyenèche', 0, 13, 'LOC'), ('Carmen', 18, 24, 'LOC'), ('Paris', 32, 37, 'LOC'), ('Friedland 15', 46, 58, 'MISC'), ('Sté Ste des Coteauxde Bois de Boulogne', 66, 105, 'LOC'), ('Longchamps', 112, 122, 'LOC'), ('siégeà Paris', 124, 138, 'ORG'), (\"rue del'\", 140, 148, 'LOC'), ('Osly 9', 148, 154, 'MISC')]\n"
     ]
    }
   ],
   "source": [
    "doc_2 = nlp(test_string_2)\n",
    "# On stocke les informations relatives au NER\n",
    "ents_2 = [(e.text, e.start_char, e.end_char, e.label_) for e in doc_2.ents]\n",
    "print(f\"Entités extraites par la chaîne de traitement spaCy : {ents}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d74dadc",
   "metadata": {},
   "source": [
    "On cherche à corriger tous les tokens qui ne sont pas des entités :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d07a77e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token : (\n",
      "Indice de confiance pour la correction : 0.0\n",
      "Correction : (\n",
      "Candidats trouvées pour la correction : {'('}\n",
      "-----\n",
      "Token : à\n",
      "Indice de confiance pour la correction : 0.0\n",
      "Correction : an\n",
      "Candidats trouvées pour la correction : {'af', 'ao', 'an', 'av', 'ai', 'al', 'ab', 'ar', 'ap', 'au', 'aa', 'as', 'ae', 'ah', 'aw', 'am', 'ad', 'az', 'ak', 'ay', 'ag', 'at', 'ac'}\n",
      "-----\n",
      "Token : )\n",
      "Indice de confiance pour la correction : 0.0\n",
      "Correction : )\n",
      "Candidats trouvées pour la correction : {')'}\n",
      "-----\n",
      "Token : dt\n",
      "Indice de confiance pour la correction : 0.0\n",
      "Correction : de\n",
      "Candidats trouvées pour la correction : {'de', 'it', 'di', 'et', 'du', 'ut', 'dy', 'det', 'da', 'dat', 'dit', 'do', 'at', 'dot'}\n",
      "-----\n",
      "Token : à\n",
      "Indice de confiance pour la correction : 0.0\n",
      "Correction : an\n",
      "Candidats trouvées pour la correction : {'af', 'ao', 'an', 'av', 'ai', 'al', 'ab', 'ar', 'ap', 'au', 'aa', 'as', 'ae', 'ah', 'aw', 'am', 'ad', 'az', 'ak', 'ay', 'ag', 'at', 'ac'}\n",
      "-----\n",
      "Token : ,\n",
      "Indice de confiance pour la correction : 0.0\n",
      "Correction : ,\n",
      "Candidats trouvées pour la correction : {','}\n",
      "-----\n",
      "Token : avenue\n",
      "Indice de confiance pour la correction : 0.0\n",
      "Correction : avene\n",
      "Candidats trouvées pour la correction : {'avene', 'avenne'}\n",
      "-----\n",
      "Token : ,\n",
      "Indice de confiance pour la correction : 0.0\n",
      "Correction : ,\n",
      "Candidats trouvées pour la correction : {','}\n",
      "-----\n",
      "Token : à\n",
      "Indice de confiance pour la correction : 0.0\n",
      "Correction : an\n",
      "Candidats trouvées pour la correction : {'af', 'ao', 'an', 'av', 'ai', 'al', 'ab', 'ar', 'ap', 'au', 'aa', 'as', 'ae', 'ah', 'aw', 'am', 'ad', 'az', 'ak', 'ay', 'ag', 'at', 'ac'}\n",
      "-----\n",
      "Token : la\n",
      "Indice de confiance pour la correction : 3.079935172113426e-05\n",
      "Correction : la\n",
      "Candidats trouvées pour la correction : {'la'}\n",
      "-----\n",
      "Token : et\n",
      "Indice de confiance pour la correction : 2.984959197642968e-06\n",
      "Correction : et\n",
      "Candidats trouvées pour la correction : {'et'}\n",
      "-----\n",
      "Token : de\n",
      "Indice de confiance pour la correction : 0.0002661362484625764\n",
      "Correction : de\n",
      "Candidats trouvées pour la correction : {'de'}\n",
      "-----\n",
      "Token : ,\n",
      "Indice de confiance pour la correction : 0.0\n",
      "Correction : ,\n",
      "Candidats trouvées pour la correction : {','}\n",
      "-----\n",
      "Token : ,\n",
      "Indice de confiance pour la correction : 0.0\n",
      "Correction : ,\n",
      "Candidats trouvées pour la correction : {','}\n",
      "-----\n",
      "Token : ,\n",
      "Indice de confiance pour la correction : 0.0\n",
      "Correction : ,\n",
      "Candidats trouvées pour la correction : {','}\n",
      "-----\n",
      "Token : de\n",
      "Indice de confiance pour la correction : 0.0002661362484625764\n",
      "Correction : de\n",
      "Candidats trouvées pour la correction : {'de'}\n",
      "-----\n",
      "Token : 3\n",
      "Indice de confiance pour la correction : 0.0\n",
      "Correction : 3\n",
      "Candidats trouvées pour la correction : {'3'}\n",
      "-----\n",
      "Token : paralles\n",
      "Indice de confiance pour la correction : 0.0\n",
      "Correction : pailles\n",
      "Candidats trouvées pour la correction : {'miralles', 'paraclet', 'pailles', 'parades', 'prallet', 'maralle', 'perales'}\n",
      "-----\n",
      "Token : de\n",
      "Indice de confiance pour la correction : 0.0002661362484625764\n",
      "Correction : de\n",
      "Candidats trouvées pour la correction : {'de'}\n",
      "-----\n",
      "Token : terrainmet\n",
      "Indice de confiance pour la correction : 0.0\n",
      "Correction : terrainmet\n",
      "Candidats trouvées pour la correction : {'terrainmet'}\n",
      "-----\n",
      "Token : 1808\n",
      "Indice de confiance pour la correction : 0.0\n",
      "Correction : 1808\n",
      "Candidats trouvées pour la correction : {'1808'}\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "spell_french = SpellChecker(language='fr')\n",
    "\n",
    "# On itère dans le document spaCy\n",
    "for sent in doc_2.sents:\n",
    "    # On itère sur les tokens\n",
    "    for token in sent:\n",
    "        # Si le token n'a pas d'entité, alors on corrige\n",
    "        if not token.ent_type_:\n",
    "            print(f'Token : {token}')\n",
    "            # TODO: comprendre pourquoi cette fonction ne renvoie pas de valeur (seulement 0.0)\n",
    "            print(f'Indice de confiance pour la correction : {spell_custom_dictionary.word_usage_frequency(str(token))}')\n",
    "            print(f'Correction : {spell_custom_dictionary.correction(str(token))}')\n",
    "            print(f'Candidats trouvées pour la correction : {spell_custom_dictionary.candidates(str(token))}')\n",
    "            print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec8e18f",
   "metadata": {},
   "source": [
    "Pour `paralles`, on attendait la correction `parcelles`. Pour `terrainmet`, on attendait `terrain met`, met étant une autre erreur de transcription automatique.\n",
    "\n",
    "Les `à` sont corrigés en `a` : cela n'est pas souhaitable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
